import os
import re
import time
import logging
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator, MyMemoryTranslator
from http.server import HTTPServer, BaseHTTPRequestHandler
import psycopg2
import hashlib
import threading

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")
CHANNEL_IDS = ["@time_n_John", "@finanosint"]

SOURCES = [
    {"name": "E3G", "url": "https://www.e3g.org/feed/"},
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "Reuters Institute", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss.xml"},
    {"name": "Chatham House ‚Äì Russia", "url": "https://www.chathamhouse.org/topics/russia/rss.xml"},
    {"name": "Chatham House ‚Äì Europe", "url": "https://www.chathamhouse.org/topics/europe/rss.xml"},
    {"name": "Chatham House ‚Äì International Security", "url": "https://www.chathamhouse.org/topics/international-security/rss.xml"},
    {"name": "CSIS", "url": "https://www.csis.org/rss.xml"},
    {"name": "Atlantic Council", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "RAND Corporation", "url": "https://www.rand.org/content/rand/www/jcr:content/par/rss_feed.rss"},
    {"name": "CFR", "url": "https://www.cfr.org/rss/"},
    {"name": "The Economist", "url": "https://www.economist.com/latest/rss.xml"},
    {"name": "Bloomberg Politics", "url": "https://www.bloomberg.com/politics/feeds/site.xml"},
    {"name": "Carnegie Endowment", "url": "https://carnegieendowment.org/rss.xml"},
    {"name": "BBC Future Planet", "url": "https://feeds.bbci.co.uk/news/science_and_environment/rss.xml"},
]

KEYWORDS = [
    r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bsanction[s]?\b", r"\bgazprom\b",
    r"\bnord\s?stream\b", r"\bwagner\b", r"\blavrov\b", r"\bshoigu\b",
    r"\bmedvedev\b", r"\bpeskov\b", r"\bnato\b", r"\beuropa\b", r"\busa\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b",
    r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b",
    r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b",
    r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b",
    r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b",
    r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b",
    r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b",
    r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b",
    r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b",
    r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b",
    r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b",
    r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b",
    r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b",
    r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b",
    r"\bhour ago\b", r"\b—á–∞—Å –Ω–∞–∑–∞–¥\b", r"\bminutos atr√°s\b", r"\bÂ∞èÊó∂Ââç\b",
    r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b",
    r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b",
    r"\bbinance coin\b", r"\bbnb\b", r"\busdt\b", r"\btether\b",
    r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b",
    r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b",
    r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b",
    r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b",
    r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b",
    r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b",
    r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b",
    r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b",
    r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b",
    r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b",
    r"\bÂàöÂàö\b", r"\bÿØŸÇÿßÿ¶ŸÇ ŸÖÿ∂ÿ™\b",
    r"\bpandemic\b", r"\b–ø–∞–Ω–¥–µ–º–∏—è\b", r"\bÁñ´ÊÉÖ\b", r"\bÿ¨ÿßÿ¶ÿ≠ÿ©\b",
    r"\boutbreak\b", r"\b–≤—Å–ø—ã—à–∫–∞\b", r"\b—ç–ø–∏–¥–µ–º–∏—è\b", r"\bepidemic\b",
    r"\bvirus\b", r"\b–≤–∏—Ä—É—Å\b", r"\b–≤–∏—Ä—É—Å—ã\b", r"\bÂèòÂºÇÊ†™\b",
    r"\bvaccine\b", r"\b–≤–∞–∫—Ü–∏–Ω–∞\b", r"\bÁñ´Ëãó\b", r"\bŸÑŸÇÿßÿ≠\b",
    r"\bbooster\b", r"\b–±—É—Å—Ç–µ—Ä\b", r"\b—Ä–µ–≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è\b",
    r"\bquarantine\b", r"\b–∫–∞—Ä–∞–Ω—Ç–∏–Ω\b", r"\bÈöîÁ¶ª\b", r"\bÿ≠ÿ¨ÿ± ÿµÿ≠Ÿä\b",
    r"\blockdown\b", r"\b–ª–æ–∫–¥–∞—É–Ω\b", r"\bÂ∞ÅÈîÅ\b",
    r"\bmutation\b", r"\b–º—É—Ç–∞—Ü–∏—è\b", r"\bÂèòÂºÇ\b",
    r"\bstrain\b", r"\b—à—Ç–∞–º–º\b", r"\bomicron\b", r"\bdelta\b",
    r"\bbiosafety\b", r"\b–±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\b", r"\bÁîüÁâ©ÂÆâÂÖ®\b",
    r"\blab leak\b", r"\b–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —É—Ç–µ—á–∫–∞\b", r"\bÂÆûÈ™åÂÆ§Ê≥ÑÊºè\b",
    r"\bgain of function\b", r"\b—É—Å–∏–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\b",
    r"\bwho\b", r"\b–≤–æ–∑\b", r"\bcdc\b", r"\b—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\b",
    r"\binfection rate\b", r"\b–∑–∞—Ä–∞–∑–Ω–æ—Å—Ç—å\b", r"\bÊ≠ª‰∫°Áéá\b",
    r"\bhospitalization\b", r"\b–≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è\b",
    r"\bŸÇÿ®ŸÑ ÿ≥ÿßÿπÿßÿ™\b", r"\bÂàöÂàöÊä•Âëä\b"
]

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(message)s")
log = logging.getLogger()

# --- –§—É–Ω–∫—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å –ë–î ---
def get_db_conn():
    return psycopg2.connect(DATABASE_URL, sslmode='require')

def is_seen(link):
    h = hashlib.sha256(link.encode()).hexdigest()
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT 1 FROM seen_links WHERE link_hash = %s", (h,))
            return cur.fetchone() is not None

def mark_seen(link):
    h = hashlib.sha256(link.encode()).hexdigest()
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("INSERT INTO seen_links (link_hash) VALUES (%s) ON CONFLICT DO NOTHING", (h,))
        conn.commit()

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def translate(text):
    if not text.strip(): return text
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except:
        try:
            return MyMemoryTranslator(source='auto', target='ru').translate(text)
        except:
            return text

def get_prefix(name):
    name = name.lower()
    prefixes = {
        "e3g": "E3G",
        "foreign affairs": "FOREIGNAFFAIRS",
        "reuters": "REUTERS",
        "bruegel": "BRUEGEL",
        "chatham house": "CHATHAM" if "security" not in name else ("CHATHAM_RU" if "russia" in name else "CHATHAM_EU"),
        "csis": "CSIS",
        "atlantic": "ATLANTICCOUNCIL",
        "rand": "RAND",
        "cfr": "CFR",
        "economist": "ECONOMIST",
        "bloomberg": "BLOOMBERG",
        "carnegie": "CARNEGIE",
        "bbc": "BBC"
    }
    for key, prefix in prefixes.items():
        if key in name:
            return prefix
    return name.split()[0].upper()

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ---
def fetch_news():
    headers = {"User-Agent": "Mozilla/5.0"}
    messages = []
    for src in SOURCES:
        try:
            resp = requests.get(src["url"].strip(), timeout=20, headers=headers)
            if resp.status_code != 200:
                log.warning(f"{src['name']}: {resp.status_code}")
                continue
            soup = BeautifulSoup(resp.content, "xml")
            for item in soup.find_all("item"):
                link = (item.link and item.link.get_text().strip()) or ""
                if not link: continue
                link = link.split('?')[0].rstrip('/')
                if is_seen(link): continue

                title = (item.title and item.title.get_text().strip()) or ""
                if not title: continue
                if not any(re.search(kw, title, re.IGNORECASE) for kw in KEYWORDS): continue

                desc = ""
                if item.description:
                    raw = BeautifulSoup(item.description.get_text(), "html.parser").get_text()
                    desc = re.split(r'(?<=[.!?])\s+', raw.strip())[0] if raw.strip() else raw[:200]
                if not desc.strip(): continue

                ru_title = translate(title).replace("\\", "")
                ru_desc = translate(desc).replace("\\", "")
                prefix = get_prefix(src["name"])
                msg = f"<b>{prefix}</b>: {ru_title}\n\n{ru_desc}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {link}"
                messages.append((msg, link))

        except Exception as e:
            log.error(f"{src['name']}: {e}")
    return messages

def send_telegram(text):
    success = True
    for cid in CHANNEL_IDS:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        data = {
            "chat_id": cid,
            "text": text,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }
        try:
            r = requests.post(url, data=data, timeout=10)
            log.info(f"‚úÖ {cid}: {r.status_code}")
            if r.status_code != 200: success = False
        except Exception as e:
            log.error(f"‚ùå {cid}: {e}")
            success = False
    return success

class HealthHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b"OK")

def start_server():
    port = int(os.environ.get("PORT", 10000))
    HTTPServer(("0.0.0.0", port), HealthHandler).serve_forever()

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS seen_links (
                    link_hash VARCHAR(64) PRIMARY KEY,
                    processed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                )
            """)
        conn.commit()

    threading.Thread(target=start_server, daemon=True).start()
    log.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω.")

    while True:
        for msg, link in fetch_news():
            if send_telegram(msg):
                mark_seen(link)
            time.sleep(1)
        log.info("‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω.")
        time.sleep(60)
