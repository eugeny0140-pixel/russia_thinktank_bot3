import os
import re
import time
import logging
import threading
import requests
import sqlite3
import hashlib
from datetime import datetime, timezone
from http.server import HTTPServer, BaseHTTPRequestHandler
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator, MyMemoryTranslator
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

# ============= –ù–ê–°–¢–†–û–ô–ö–ò =============
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "")
CHANNEL_IDS = [cid.strip() for cid in os.getenv("CHANNEL_IDS", "@time_n_John,@finanosint").split(",") if cid.strip()]
DRY_RUN = os.getenv("DRY_RUN", "0") == "1"
RENDER_APP_URL = os.getenv("RENDER_APP_URL", "")  # URL –≤–∞—à–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ Render –¥–ª—è keep-alive

# –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ‚Äî —É–±—Ä–∞–Ω—ã –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ URL
SOURCES = [
    {"name": "Good Judgment", "url": "https://goodjudgment.com/feed/"},
    {"name": "Johns Hopkins", "url": "https://www.centerforhealthsecurity.org/feed.xml"},
    {"name": "Metaculus", "url": "https://www.metaculus.com/feed/"},
    {"name": "DNI Global Trends", "url": "https://www.dni.gov/index.php/gt2040-home?format=feed&type=rss"},
    {"name": "RAND Corporation", "url": "https://www.rand.org/feed/"},
    {"name": "World Economic Forum", "url": "https://www.weforum.org/feed/"},
    {"name": "CSIS", "url": "https://www.csis.org/feed/"},
    {"name": "Atlantic Council", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "Chatham House", "url": "https://www.chathamhouse.org/feeds/all"},
    {"name": "The Economist", "url": "https://www.economist.com/the-world-this-week/rss.xml"},
    {"name": "Bloomberg Politics", "url": "https://www.bloomberg.com/politics/feeds/site.xml"},
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss"},
    {"name": "BBC Future", "url": "https://feeds.bbci.co.uk/news/science_and_environment/rss.xml"},
    {"name": "Future Timeline", "url": "https://www.futuretimeline.net/feed/"},
    {"name": "Carnegie Endowment", "url": "https://carnegieendowment.org/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss.xml"},
    {"name": "E3G", "url": "https://www.e3g.org/feed/"},
]

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
KEYWORDS = [
     r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bsanction[s]?\b", r"\bgazprom\b",
    r"\bnord\s?stream\b", r"\bwagner\b", r"\blavrov\b", r"\bshoigu\b",
    r"\bmedvedev\b", r"\bpeskov\b", r"\bnato\b", r"\beuropa\b", r"\busa\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b",
    r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b",
    r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b",
    r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b",
    r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b",
    r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b",
    r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b",
    r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b",
    r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b",
    r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b",
    r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b",
    r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b",
    r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b",
    r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b",
    r"\bhour ago\b", r"\b—á–∞—Å –Ω–∞–∑–∞–¥\b", r"\bminutos atr√°s\b", r"\bÂ∞èÊó∂Ââç\b",
    r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b",
    r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b",
    r"\bbinance coin\b", r"\bbnb\b", r"\busdt\b", r"\btether\b",
    r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b",
    r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b",
    r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b",
    r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b",
    r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b",
    r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b",
    r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b",
    r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b",
    r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b",
    r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b",
    r"\bÂàöÂàö\b", r"\bÿØŸÇÿßÿ¶ŸÇ ŸÖÿ∂ÿ™\b",
    r"\bpandemic\b", r"\b–ø–∞–Ω–¥–µ–º–∏—è\b", r"\bÁñ´ÊÉÖ\b", r"\bÿ¨ÿßÿ¶ÿ≠ÿ©\b",
    r"\boutbreak\b", r"\b–≤—Å–ø—ã—à–∫–∞\b", r"\b—ç–ø–∏–¥–µ–º–∏—è\b", r"\bepidemic\b",
    r"\bvirus\b", r"\b–≤–∏—Ä—É—Å\b", r"\b–≤–∏—Ä—É—Å—ã\b", r"\bÂèòÂºÇÊ†™\b",
    r"\bvaccine\b", r"\b–≤–∞–∫—Ü–∏–Ω–∞\b", r"\bÁñ´Ëãó\b", r"\bŸÑŸÇÿßÿ≠\b",
    r"\bbooster\b", r"\b–±—É—Å—Ç–µ—Ä\b", r"\b—Ä–µ–≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è\b",
    r"\bquarantine\b", r"\b–∫–∞—Ä–∞–Ω—Ç–∏–Ω\b", r"\bÈöîÁ¶ª\b", r"\bÿ≠ÿ¨ÿ± ÿµÿ≠Ÿä\b",
    r"\blockdown\b", r"\b–ª–æ–∫–¥–∞—É–Ω\b", r"\bÂ∞ÅÈîÅ\b",
    r"\bmutation\b", r"\b–º—É—Ç–∞—Ü–∏—è\b", r"\bÂèòÂºÇ\b",
    r"\bstrain\b", r"\b—à—Ç–∞–º–º\b", r"\bomicron\b", r"\bdelta\b",
    r"\bbiosafety\b", r"\b–±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\b", r"\bÁîüÁâ©ÂÆâÂÖ®\b",
    r"\blab leak\b", r"\b–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —É—Ç–µ—á–∫–∞\b", r"\bÂÆûÈ™åÂÆ§Ê≥ÑÊºè\b",
    r"\bgain of function\b", r"\b—É—Å–∏–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\b",
    r"\bwho\b", r"\b–≤–æ–∑\b", r"\bcdc\b", r"\b—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\b",
    r"\binfection rate\b", r"\b–∑–∞—Ä–∞–∑–Ω–æ—Å—Ç—å\b", r"\bÊ≠ª‰∫°Áéá\b", r"\bhospitalization\b", r"\b–≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è\b", r"\bŸÇÿ®ŸÑ ÿ≥ÿßÿπÿßÿ™\b", r"\bÂàöÂàöÊä•Âëä\b"
]

DB_PATH = "seen_titles.db"
INTERVAL_SEC = 300  # 5 –º–∏–Ω—É—Ç
MAX_DB_SIZE = 5000
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
MAX_WORKERS = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
TELEGRAM_MAX_CHARS = 4096  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram

# ============= –õ–û–ì–ò–†–û–í–ê–ù–ò–ï =============
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
log = logging.getLogger()

# ============= –ë–ê–ó–ê –î–ê–ù–ù–´–• =============
def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS seen_titles (
                title_hash TEXT PRIMARY KEY,
                processed_at TEXT NOT NULL
            )
        """)
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
        conn.execute("CREATE INDEX IF NOT EXISTS idx_processed_at ON seen_titles(processed_at)")
        conn.commit()

def normalize_title(title: str) -> str:
    return re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9—ë–Å]", "", title.lower()).strip()

def is_title_seen(title: str) -> bool:
    norm = normalize_title(title)
    if not norm:
        return False
    h = hashlib.sha256(norm.encode("utf-8")).hexdigest()
    with sqlite3.connect(DB_PATH, timeout=10) as conn:
        cur = conn.execute("SELECT 1 FROM seen_titles WHERE title_hash = ?", (h,))
        return cur.fetchone() is not None

def mark_title_seen(title: str):
    norm = normalize_title(title)
    if not norm:
        return
    h = hashlib.sha256(norm.encode("utf-8")).hexdigest()
    now = datetime.now(timezone.utc).isoformat()
    try:
        with sqlite3.connect(DB_PATH, timeout=10) as conn:
            conn.execute(
                "INSERT OR IGNORE INTO seen_titles (title_hash, processed_at) VALUES (?, ?)",
                (h, now)
            )
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
            conn.execute(f"""
                DELETE FROM seen_titles
                WHERE rowid NOT IN (
                    SELECT rowid FROM seen_titles
                    ORDER BY processed_at DESC
                    LIMIT {MAX_DB_SIZE}
                )
            """)
            conn.commit()
    except sqlite3.OperationalError as e:
        log.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö: {e}. –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ 1 —Å–µ–∫—É–Ω–¥—É")
        time.sleep(1)
        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫—É –æ–¥–∏–Ω —Ä–∞–∑
        try:
            with sqlite3.connect(DB_PATH, timeout=10) as conn:
                conn.execute(
                    "INSERT OR IGNORE INTO seen_titles (title_hash, processed_at) VALUES (?, ?)",
                    (h, now)
                )
                conn.commit()
        except Exception as e2:
            log.error(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –ë–î —Ç–∞–∫–∂–µ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e2}")

# ============= –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò =============
def clean_text(t: str) -> str:
    return re.sub(r"\s+", " ", t).strip()

def translate_to_russian(text: str) -> str:
    if not text or not text.strip():
        return ""
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ —Å GoogleTranslator
        result = GoogleTranslator(source='auto', target='ru').translate(text)
        if result and result.strip():
            return result.strip()
    except Exception as e1:
        log.warning(f"GoogleTranslator failed: {e1}")
    
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ —Å MyMemoryTranslator
        result = MyMemoryTranslator(source='auto', target='ru').translate(text)
        if result and result.strip():
            return result.strip()
    except Exception as e2:
        log.warning(f"MyMemoryTranslator also failed: {e2}")
    
    # –ï—Å–ª–∏ –æ–±–∞ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    return text.strip()

def html_escape(text: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ HTML-—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    return text.replace("&", "&amp;").replace("<", "<").replace(">", ">").replace('"', "&quot;")

def truncate_message(text: str, max_length: int = TELEGRAM_MAX_CHARS) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã, —Å–æ—Ö—Ä–∞–Ω—è—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å HTML-—Ç–µ–≥–æ–≤"""
    if len(text) <= max_length:
        return text
    
    # –ü—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–µ–∑–∞—Ç—å –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ª–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    truncated = text[:max_length]
    last_newline = truncated.rfind("\n")
    if last_newline > max_length * 0.8:  # –ï—Å–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å –±–ª–∏–∑–∫–æ –∫ –∫–æ–Ω—Ü—É
        truncated = truncated[:last_newline]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ HTML-—Ç–µ–≥–∏
    open_tags = []
    pos = 0
    while pos < len(truncated):
        if truncated[pos] == "<":
            end_tag = truncated.find(">", pos)
            if end_tag != -1:
                tag_content = truncated[pos+1:end_tag]
                if tag_content.startswith("/"):
                    # –ó–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥
                    if open_tags:
                        open_tags.pop()
                elif not tag_content.endswith("/"):
                    # –û—Ç–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ (–Ω–µ —Å–∞–º–æ–∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π—Å—è)
                    tag_name = tag_content.split()[0]
                    open_tags.append(tag_name)
                pos = end_tag
        pos += 1
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
    for tag in reversed(open_tags):
        truncated += f"</{tag}>"
    
    truncated += "..."
    return truncated

def keep_awake():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞—Å—ã–ø–∞–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ Render.com"""
    if not RENDER_APP_URL:
        log.info("RENDER_APP_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. Keep-alive –æ—Ç–∫–ª—é—á–µ–Ω.")
        return
        
    log.info(f"Keep-alive –∞–∫—Ç–∏–≤–µ–Ω. URL –¥–ª—è –ø–∏–Ω–≥–∞: {RENDER_APP_URL}")
    while True:
        try:
            requests.get(RENDER_APP_URL, timeout=10)
            log.debug("‚úÖ Keep-alive –∑–∞–ø—Ä–æ—Å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å keep-alive –∑–∞–ø—Ä–æ—Å: {e}")
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç (Render –∑–∞—Å—ã–ø–∞–µ—Ç –ø–æ—Å–ª–µ 15 –º–∏–Ω—É—Ç –±–µ–∑–¥–µ–π—Å—Ç–≤–∏—è)
        time.sleep(600)

# ============= –ü–û–õ–£–ß–ï–ù–ò–ï –ù–û–í–û–°–¢–ï–ô =============
def process_source(src):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    headers = {"User-Agent": USER_AGENT}
    items = []
    
    try:
        log.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {src['name']}")
        resp = requests.get(src["url"], headers=headers, timeout=20)
        
        if resp.status_code != 200:
            log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {src['name']}: HTTP {resp.status_code}")
            return items
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è DNI Global Trends (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML –≤–º–µ—Å—Ç–æ XML)
        content_type = resp.headers.get('Content-Type', '').lower()
        use_html_parser = 'html' in content_type or 'dni.gov' in src['url']
        
        try:
            # –î–ª—è DNI Global Trends –∏—Å–ø–æ–ª—å–∑—É–µ–º html.parser –≤–º–µ—Å—Ç–æ xml
            parser = "html.parser" if use_html_parser else "xml"
            soup = BeautifulSoup(resp.content, parser)
            
            # –î–ª—è DNI Global Trends —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            if 'dni.gov' in src['url'] and use_html_parser:
                # –ò—â–µ–º RSS-—Å—Å—ã–ª–∫–∏ –≤ HTML
                rss_links = soup.find_all('link', {'type': 'application/rss+xml'})
                if rss_links:
                    rss_url = rss_links[0].get('href')
                    if not rss_url.startswith('http'):
                        rss_url = 'https://www.dni.gov' + rss_url
                    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π RSS
                    rss_resp = requests.get(rss_url, headers=headers, timeout=15)
                    if rss_resp.status_code == 200:
                        soup = BeautifulSoup(rss_resp.content, "xml")
            elif use_html_parser:
                log.warning(f"{src['name']} –≤–µ—Ä–Ω—É–ª HTML –≤–º–µ—Å—Ç–æ XML. –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ HTML.")
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {src['name']}: {e}. –ü—Ä–æ–±—É–µ–º html.parser.")
            soup = BeautifulSoup(resp.content, "html.parser")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–æ–æ–±—â–µ —ç–ª–µ–º–µ–Ω—Ç—ã item
        items_found = soup.find_all("item")
        if not items_found:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ entry –¥–ª—è Atom —Ñ–∏–¥–æ–≤
            items_found = soup.find_all("entry")
        
        if not items_found:
            # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è HTML-—Å—Ç—Ä–∞–Ω–∏—Ü
            if use_html_parser and 'dni.gov' in src['url']:
                # –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ DNI
                articles = soup.select('article, .news-item, .post')
                for article in articles[:10]:  # –ë–µ—Ä–µ–º –Ω–µ –±–æ–ª–µ–µ 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π
                    title_elem = article.find('h2', class_='title') or article.find('h3') or article.find('a', class_='title')
                    if title_elem:
                        title = clean_text(title_elem.get_text())
                        link = title_elem.get('href', '') if title_elem.name == 'a' else ''
                        if link and not link.startswith('http'):
                            link = 'https://www.dni.gov' + link
                        desc_elem = article.find('p', class_='summary') or article.find('div', class_='content') or article.find('p')
                        desc = clean_text(desc_elem.get_text()) if desc_elem else ""
                        
                        if title and link:
                            items.append((title, link, desc, src))
            else:
                log.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {src['name']}")
            return items
        
        for item in items_found:
            try:
                title = ""
                link = ""
                desc = ""
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ RSS —Ñ–æ—Ä–º–∞—Ç–∞
                if item.name == "item":
                    title = clean_text(item.title.get_text()) if item.title else ""
                    # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –∞—Ç—Ä–∏–±—É—Ç–∞
                    link = ""
                    if item.link:
                        if isinstance(item.link, str):
                            link = item.link.strip()
                        elif hasattr(item.link, 'get_text'):
                            link_text = item.link.get_text().strip()
                            link = link_text if link_text else item.link.get("href", "").strip()
                        elif hasattr(item.link, 'get'):
                            link = item.link.get("href", "").strip()
                    
                    # –ü–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è
                    desc_tag = item.find("description") or item.find("content:encoded") or item.find("content")
                    if desc_tag:
                        raw = desc_tag.get_text()
                        # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
                        clean_desc = BeautifulSoup(raw, "html.parser").get_text()
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–ª–∏ –ø–µ—Ä–≤—ã–µ 250 —Å–∏–º–≤–æ–ª–æ–≤
                        sentences = re.split(r'(?<=[.!?])\s+', clean_desc.strip())
                        desc = sentences[0] if sentences else clean_desc[:250]
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ Atom —Ñ–æ—Ä–º–∞—Ç–∞
                elif item.name == "entry":
                    title = clean_text(item.title.get_text()) if item.title else ""
                    link_tag = item.find("link", rel="alternate") or item.find("link")
                    link = link_tag.get("href", "") if link_tag else ""
                    
                    # –ü–æ–∏—Å–∫ –æ–ø–∏—Å–∞–Ω–∏—è
                    desc_tag = item.find("summary") or item.find("content")
                    if desc_tag:
                        raw = desc_tag.get_text()
                        clean_desc = BeautifulSoup(raw, "html.parser").get_text()
                        sentences = re.split(r'(?<=[.!?])\s+', clean_desc.strip())
                        desc = sentences[0] if sentences else clean_desc[:250]
                
                if not title or not link:
                    continue
                
                items.append((title, link, desc, src))
            except Exception as e:
                log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ {src['name']}: {e}")
                continue
    
    except Exception as e:
        log.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {src['name']}: {e}")
    
    return items

def fetch_news():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏"""
    all_items = []
    source_items = []
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_source = {executor.submit(process_source, src): src for src in SOURCES}
        for future in as_completed(future_to_source):
            src = future_to_source[future]
            try:
                items = future.result()
                source_items.extend(items)
            except Exception as e:
                log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {src['name']}: {e}")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
    for title, link, desc, src in source_items:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤–∏–¥–µ–ª–∏ –ª–∏ –º—ã —ç—Ç—É –Ω–æ–≤–æ—Å—Ç—å —Ä–∞–Ω–µ–µ
        if is_title_seen(title):
            continue
        
        # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω–æ–µ –î–û —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        mark_title_seen(title)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if not any(re.search(kw, title, re.IGNORECASE) for kw in KEYWORDS):
            continue
        
        # –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
        ru_title = translate_to_russian(title)
        ru_desc = translate_to_russian(desc) if desc else ""
        
        # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ HTML
        safe_title = html_escape(ru_title)
        safe_desc = html_escape(ru_desc)
        safe_link = html_escape(link)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ
        source_bold = f"<b>{src['name']}</b>"
        msg = f"{source_bold}\n\n<strong>{safe_title}</strong>\n\n{safe_desc}\n\n<a href='{safe_link}'>–ò—Å—Ç–æ—á–Ω–∏–∫</a>"
        
        # –û–±—Ä–µ–∑–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
        msg = truncate_message(msg)
        
        all_items.append((msg, title))
    
    log.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_items)} –Ω–æ–≤—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
    return all_items

# ============= –û–¢–ü–†–ê–í–ö–ê –í TELEGRAM =============
def send_to_telegram(text: str, channel_ids: list) -> bool:
    if DRY_RUN:
        log.info(f"[–¢–ï–°–¢] –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏:\n{text[:200]}...\n")
        return True
    
    success = True
    for ch_id in channel_ids:
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ URL API
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        payload = {
            "chat_id": ch_id,
            "text": text,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }
        
        # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ 429
        max_retries = 5
        for attempt in range(max_retries):
            try:
                r = requests.post(url, data=payload, timeout=30)
                
                if r.status_code == 200:
                    log.info(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {ch_id}")
                    break
                elif r.status_code == 429:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ "Too Many Requests"
                    try:
                        response = r.json()
                        retry_after = response.get('parameters', {}).get('retry_after', 30)
                    except:
                        retry_after = 30
                    
                    log.warning(f"‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è {ch_id}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {retry_after} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(retry_after + attempt * 5)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                    continue
                elif r.status_code == 400 and "message is too long" in r.text.lower():
                    # –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –ø—ã—Ç–∞–µ–º—Å—è –µ–≥–æ –æ–±—Ä–µ–∑–∞—Ç—å
                    log.warning(f"–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ –¥–ª—è {ch_id}. –ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–µ–∑–∫–∏...")
                    text = truncate_message(text, TELEGRAM_MAX_CHARS - 100)  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å
                    payload["text"] = text
                    continue
                else:
                    log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ {ch_id}: HTTP {r.status_code}, –æ—Ç–≤–µ—Ç: {r.text}")
                    success = False
                    break
            except Exception as e:
                log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {ch_id}: {e}")
                success = False
                break
        else:
            log.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ {ch_id}")
            success = False
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏ –≤ —Ä–∞–∑–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
        time.sleep(2.0)
    
    return success

# ============= HEALTH CHECK =============
class HealthHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header("Content-type", "application/json")
        self.end_headers()
        
        status = {
            "status": "ok",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "channels": CHANNEL_IDS,
            "sources_count": len(SOURCES),
            "db_path": DB_PATH
        }
        self.wfile.write(json.dumps(status).encode('utf-8'))
    
    def log_message(self, format, *args):
        pass

def start_health_server():
    port = int(os.environ.get("PORT", 10000))
    server = HTTPServer(("0.0.0.0", port), HealthHandler)
    log.info(f"Health check server –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    server.serve_forever()

# ============= –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ =============
def main_loop():
    init_db()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if not TELEGRAM_TOKEN:
        log.error("‚ùå TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        return
    
    if not CHANNEL_IDS:
        log.error("‚ùå CHANNEL_IDS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ü—Ä–∏–º–µ—Ä: CHANNEL_IDS=@channel1,@channel2")
        return
    
    log.info(f"üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ö–∞–Ω–∞–ª—ã: {', '.join(CHANNEL_IDS)}")
    log.info(f"üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∫–∞–∂–¥—ã–µ {INTERVAL_SEC} —Å–µ–∫—É–Ω–¥")
    
    if DRY_RUN:
        log.info("üß™ –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (DRY_RUN) –≤–∫–ª—é—á–µ–Ω - —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è")
    
    if RENDER_APP_URL:
        log.info("üí§ Keep-alive –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞—Å—ã–ø–∞–Ω–∏—è –Ω–∞ Render.com")
    else:
        log.warning("üí§ RENDER_APP_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç –∑–∞—Å—ã–ø–∞—Ç—å –Ω–∞ Render.com.")
    
    while True:
        cycle_start = time.time()
        try:
            news = fetch_news()
            sent = 0
            total = len(news)
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —Ü–∏–∫–ª
            MAX_NEWS_PER_CYCLE = 15
            if total > MAX_NEWS_PER_CYCLE:
                log.warning(f"–ù–∞–π–¥–µ–Ω–æ {total} –Ω–æ–≤–æ—Å—Ç–µ–π, –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ {MAX_NEWS_PER_CYCLE}")
                news = news[:MAX_NEWS_PER_CYCLE]
            
            for msg, orig_title in news:
                if send_to_telegram(msg, CHANNEL_IDS):
                    sent += 1
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
                time.sleep(1.5)
            
            cycle_duration = time.time() - cycle_start
            log.info(f"‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω. –ù–∞–π–¥–µ–Ω–æ: {total}, –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {sent}, –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {cycle_duration:.1f} —Å–µ–∫")
        except Exception as e:
            log.exception(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ü–∏–∫–ª–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –∑–∞–¥–µ—Ä–∂–∫–∏
        elapsed = time.time() - cycle_start
        sleep_time = max(1, INTERVAL_SEC - elapsed)
        log.debug(f"üò¥ –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ {sleep_time:.1f} —Å–µ–∫—É–Ω–¥")
        time.sleep(sleep_time)

# ============= –ó–ê–ü–£–°–ö =============
if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ health check —Å–µ—Ä–≤–µ—Ä–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    threading.Thread(target=start_health_server, daemon=True).start()
    
    # –ó–∞–ø—É—Å–∫ keep-alive –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞—Å—ã–ø–∞–Ω–∏—è –Ω–∞ Render.com
    if RENDER_APP_URL:
        threading.Thread(target=keep_awake, daemon=True).start()
    
    # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
    main_loop()
