import os
import re
import time
import logging
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator, MyMemoryTranslator
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID", "@time_n_John")

if not TELEGRAM_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω")

# –ò—Å—Ç–æ—á–Ω–∏–∫–∏: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ URL
SOURCES = [
    {"name": "E3G", "url": "https://www.e3g.org/feed/"},
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "Reuters Institute", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss.xml"},
    {"name": "Chatham House", "url": "https://www.chathamhouse.org/rss.xml"},
    {"name": "CSIS", "url": "https://www.csis.org/rss.xml"},
    {"name": "Atlantic Council", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "RAND Corporation", "url": "https://www.rand.org/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss/"},
    {"name": "The Economist", "url": "https://www.economist.com/latest/rss.xml"},
    {"name": "Bloomberg Politics", "url": "https://www.bloomberg.com/politics/feeds/site.xml"},
]

# üîç –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—Å–æ–∫—Ä–∞—â—ë–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä ‚Äî –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
KEYWORDS = [
     # === –û—Å–Ω–æ–≤–Ω—ã–µ: –†–æ—Å—Å–∏—è, –£–∫—Ä–∞–∏–Ω–∞, –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞ ===
    r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bsanction[s]?\b", r"\bgazprom\b",
    r"\bnord\s?stream\b", r"\bwagner\b", r"\blavrov\b", r"\bshoigu\b",
    r"\bmedvedev\b", r"\bpeskov\b", r"\bnato\b", r"\beuropa\b", r"\busa\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b",

    # === 1. –°–í–û –∏ –í–æ–π–Ω–∞ ===
    r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b", 
    r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b", 
    r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b", 
    r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b", 
    r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b", 
    r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b", 
    r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b", 
    r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b", 
    r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b", 
    r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b", 
    r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b", 
    r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b", r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", {"name": "E3G", "url": "https://www.e3g.org/feed/"},
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "Reuters Institute", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss.xml"},
    {"name": "Chatham House", "url": "https://www.chathamhouse.org/rss.xml"},
    {"name": "CSIS", "url": "https://www.csis.org/rss.xml"},
    {"name": "Atlantic Council", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "RAND Corporation", "url": "https://www.rand.org/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss/"},
    {"name": "The Economist", "url": "https://www.economist.com/latest/rss.xml"},
    {"name": "Bloomberg Politics", "url": "https://www.bloomberg.com/politics/feeds/site.xml"},
]
r"\bnato\b", r"\bwar\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b"
]

seen_links = set()
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(message)s")
log = logging.getLogger()

def translate(text):
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e1:
        log.warning(f"Google Translate failed: {e1}")
        try:
            return MyMemoryTranslator(source='en', target='ru').translate(text)
        except Exception as e2:
            log.warning(f"MyMemoryTranslator failed: {e2}")
            return text

def get_prefix(name):
    name = name.lower()
    if "e3g" in name: return "e3g"
    if "foreign affairs" in name: return "foreignaffairs"
    if "reuters" in name: return "reuters"
    if "bruegel" in name: return "bruegel"
    if "chatham" in name: return "chathamhouse"
    if "csis" in name: return "csis"
    if "atlantic" in name: return "atlanticcouncil"
    if "rand" in name: return "rand"
    if "cfr" in name: return "cfr"
    if "economist" in name: return "economist"
    if "bloomberg" in name: return "bloomberg"
    return name.split()[0].lower()

def fetch_one_per_source():
    headers = {"User-Agent": "Mozilla/5.0"}
    messages = []
    for src in SOURCES:
        try:
            resp = requests.get(src["url"], timeout=20, headers=headers)
            soup = BeautifulSoup(resp.content, "xml")
            item = soup.find("item")
            if not item:
                continue

            link = (item.link and item.link.get_text().strip()) or ""
            title = (item.title and item.title.get_text().strip()) or ""
            if not title or not link or link in seen_links:
                continue

            if not any(re.search(kw, title, re.IGNORECASE) for kw in KEYWORDS):
                continue

            desc = ""
            desc_tag = item.find("description")
            if desc_tag:
                raw = BeautifulSoup(desc_tag.get_text(), "html.parser").get_text()
                sentences = re.split(r'(?<=[.!?])\s+', raw.strip())
                desc = sentences[0] if sentences else raw[:200]

            if not desc.strip():
                continue

            ru_title = translate(title)
            ru_desc = translate(desc)
            prefix = get_prefix(src["name"]).upper()
            # –§–æ—Ä–º–∞—Ç: **ATLANTICCOUNCIL**: –ó–∞–≥–æ–ª–æ–≤–æ–∫...\n\n–õ–∏–¥...\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: https://...
            msg = f"<b>{prefix}</b>: {ru_title}\n\n{ru_desc}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {link}"
            messages.append((msg, link))

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ {src['name']}: {e}")
    return messages

def send_to_telegram(text):
    # üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ URL
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    data = {
        "chat_id": CHANNEL_ID,
        "text": text,
        "parse_mode": "HTML",  # –¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞
        "disable_web_page_preview": True,
    }
    try:
        r = requests.post(url, data=data, timeout=10)
        log.info("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ" if r.status_code == 200 else f"‚ùå –û—à–∏–±–∫–∞: {r.text}")
    except Exception as e:
        log.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")

# === HTTP-—Å–µ—Ä–≤–µ—Ä –¥–ª—è Render ===
class HealthHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b"OK")
    def log_message(self, format, *args): pass

def start_server():
    port = int(os.environ.get("PORT", 10000))
    HTTPServer(("0.0.0.0", port), HealthHandler).serve_forever()

# === –ó–ê–ü–£–°–ö ===
if __name__ == "__main__":
    threading.Thread(target=start_server, daemon=True).start()
    log.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—Ä–æ–≤–µ—Ä–∫–∞ RSS –∫–∞–∂–¥—ã–µ 60 —Å–µ–∫—É–Ω–¥ (—Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è).")

    while True:
        messages = fetch_one_per_source()
        count = 0
        for msg, link in messages:
            send_to_telegram(msg)
            seen_links.add(link)
            count += 1
            time.sleep(1)
        log.info(f"‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω. –ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {count}")
        time.sleep(60)

