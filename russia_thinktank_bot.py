# russia_thinktank_bot.py
import os
import json
import re
import time
import logging
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import schedule

# ================== –ù–ê–°–¢–†–û–ô–ö–ò ==================
TELEGRAM_TOKEN = "  # ‚ö†Ô∏è –°–ö–û–†–û –ò–°–¢–ï–ß–Å–¢!
CHANNEL_ID = "@time_n_John"

# –¢–æ–ª—å–∫–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç (–ø–æ –ª–æ–≥–∞–º)
SOURCES = [
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "Reuters Institute", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss.xml"},
    {"name": "E3G", "url": "https://www.e3g.org/feed/"},
]

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ ‚Äî –≤—Å—ë, —á—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –†–§, –£–∫—Ä–∞–∏–Ω–æ–π, —Å–∞–Ω–∫—Ü–∏—è–º–∏, –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–æ–π
KEYWORDS = [
    r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bdonetsk\b", r"\bluhansk\b",
    r"\bsanction[s]?\b", r"\bembargo\b", r"\brestrict\b",
    r"\bgazprom\b", r"\bnord\s?stream\b",
    r"\bwagner\b", r"\bshoigu\b", r"\bmedvedev\b", r"\bpeskov\b", r"\blavrov\b",
    r"\bnato\b", r"\beuropa\b", r"\busa\b", r"\buk\b",
    r"\bwar\b", r"\bconflict\b", r"\bmilitary\b",
    r"\bruble\b", r"\beconomy\b", r"\benergy\b", r"\boil\b", r"\bgas\b",
]

SEEN_FILE = "seen_links.json"
MAX_SEEN = 3000
MAX_PER_RUN = 8

# ================== –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ==================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler("bot.log", encoding="utf-8"), logging.StreamHandler()]
)
log = logging.getLogger(__name__)

# ================== –§–£–ù–ö–¶–ò–ò ==================

def load_seen_links():
    if os.path.exists(SEEN_FILE):
        try:
            with open(SEEN_FILE, "r", encoding="utf-8") as f:
                return set(json.load(f)[-MAX_SEEN:])
        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è seen_links.json: {e}")
    return set()

def save_seen_link(link, seen):
    seen.add(link)
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(list(seen)[-MAX_SEEN:], f)

def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHANNEL_ID,
        "text": text,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True,
    }
    try:
        r = requests.post(url, data=payload, timeout=15)
        if r.status_code == 200:
            log.info("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
        else:
            log.error(f"–û—à–∏–±–∫–∞ Telegram: {r.text}")
    except Exception as e:
        log.error(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")

def clean_text(t):
    return re.sub(r"\s+", " ", t).strip()

def translate_to_russian(text):
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e:
        log.warning(f"–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
        return text

def get_summary(title):
    low = title.lower()
    if re.search(r"sanction|embargo|restrict", low):
        return "–í–≤–µ–¥–µ–Ω—ã –Ω–æ–≤—ã–µ —Å–∞–Ω–∫—Ü–∏–∏ –∏–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è."
    if re.search(r"war|attack|strike|bomb|conflict|military", low):
        return "–°–æ–æ–±—â–∞–µ—Ç—Å—è –æ –≤–æ–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è—Ö –∏–ª–∏ —É–¥–∞—Ä–∞—Ö."
    if re.search(r"putin|kremlin|peskov|moscow", low):
        return "–ó–∞—è–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –ö—Ä–µ–º–ª—è."
    if re.search(r"economy|rubl?e|oil|gas|gazprom|nord\s?stream|energy", low):
        return "–ù–æ–≤–æ—Å—Ç–∏ —ç–∫–æ–Ω–æ–º–∏–∫–∏, –Ω–µ—Ñ—Ç–∏, –≥–∞–∑–∞ –∏–ª–∏ —Ä—É–±–ª—è."
    if re.search(r"diplomat|talks|negotiat|meeting|lavrov", low):
        return "–î–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã –∏–ª–∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã."
    if re.search(r"wagner|shoigu|medvedev|defense", low):
        return "–°–æ–±—ã—Ç–∏—è —Å —Ä–æ—Å—Å–∏–π—Å–∫–∏–º–∏ –≤–æ–µ–Ω–Ω—ã–º–∏ –∏–ª–∏ –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏."
    if re.search(r"ukraine|zelensky|kyiv|kiev|crimea|donbas", low):
        return "–°–æ–±—ã—Ç–∏—è, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –£–∫—Ä–∞–∏–Ω–æ–π –∏ –ø—Ä–∏–ª–µ–≥–∞—é—â–∏–º–∏ —Ä–µ–≥–∏–æ–Ω–∞–º–∏."
    if re.search(r"nato|europa|european|germany|france|usa|uk", low):
        return "–†–µ–∞–∫—Ü–∏—è –∑–∞–ø–∞–¥–Ω—ã—Ö —Å—Ç—Ä–∞–Ω –∏–ª–∏ –ù–ê–¢–û –Ω–∞ —Å–æ–±—ã—Ç–∏—è —Å —É—á–∞—Å—Ç–∏–µ–º –†–æ—Å—Å–∏–∏."
    return "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –†–æ—Å—Å–∏–µ–π –∏–ª–∏ –ø–æ—Å—Ç—Å–æ–≤–µ—Ç—Å–∫–∏–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º."

def fetch_rss_news():
    seen = load_seen_links()
    result = []
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}

    for src in SOURCES:
        if len(result) >= MAX_PER_RUN:
            break
        try:
            url = src["url"].strip()
            log.info(f"–ü–∞—Ä—Å–∏–Ω–≥: {src['name']}")
            resp = requests.get(url, timeout=25, headers=headers)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.content, "xml")

            for item in soup.find_all("item"):
                if len(result) >= MAX_PER_RUN:
                    break

                title = clean_text(item.title.get_text()) if item.title else ""
                link = (item.link.get_text() or item.guid.get_text()).strip() if item.link or item.guid else ""

                if not title or not link or link in seen:
                    continue

                # –§–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –†–æ—Å—Å–∏–∏/–£–∫—Ä–∞–∏–Ω—ã/–≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∏
                if not any(re.search(kw, title, re.IGNORECASE) for kw in KEYWORDS):
                    continue

                ru_title = translate_to_russian(title)
                summary = get_summary(title)

                # üîó –ó–ê–ì–û–õ–û–í–û–ö ‚Äî –ö–õ–ò–ö–ê–ë–ï–õ–¨–ù–ê–Ø –°–°–´–õ–ö–ê, –†–ï–ó–Æ–ú–ï ‚Äî –û–ë–´–ß–ù–´–ô –¢–ï–ö–°–¢
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞—é—Ç Markdown: [, ], (, )
                safe_title = ru_title.replace("[", "\\[").replace("]", "\\]").replace("(", "\\(").replace(")", "\\)")
                msg = f"[{safe_title}]({link})\n\n{summary}"
                result.append({"msg": msg, "link": link})

        except Exception as e:
            log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {src['name']}: {e}")

    return result

def job():
    log.info("–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –†–æ—Å—Å–∏–∏...")
    news = fetch_rss_news()
    if not news:
        log.info("–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π.")
        return

    seen = load_seen_links()
    for item in news:
        send_to_telegram(item["msg"])
        save_seen_link(item["link"], seen)
        time.sleep(1.2)

# ================== –ó–ê–ü–£–°–ö –ë–û–¢–ê ==================
if __name__ == "__main__":
    log.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –†–æ—Å—Å–∏–µ–π.")
    job()
    schedule.every(30).minutes.do(job)

    while True:
        schedule.run_pending()
        time.sleep(1)

